{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50484d2-bfa4-40b6-82cd-e8bf86187cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pprint\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, DateType\n",
    "\n",
    "import utils.data_processing_bronze_table\n",
    "import utils.data_processing_silver_table\n",
    "# import utils.data_processing_gold_table\n",
    "\n",
    "from utils.data_processing_clickstream import (\n",
    "    process_bronze_clickstream,\n",
    "    process_silver_clickstream)\n",
    "\n",
    "from utils.data_processing_attributes import (\n",
    "    process_bronze_attributes,\n",
    "    process_silver_attributes)\n",
    "\n",
    "from utils.data_processing_financials import (\n",
    "    process_bronze_financials,\n",
    "    process_silver_financials)\n",
    "\n",
    "from utils.data_processing_gold_features import (\n",
    "    process_gold_customer_feature_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c91bb1-bcf0-4195-90f3-dc88806ebf8c",
   "metadata": {},
   "source": [
    "## set up pyspark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb3bc6-4166-4893-88e1-0d3140df5a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"dev\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to ERROR to hide warnings\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30206071-5f00-4c3b-be13-55c54db8e336",
   "metadata": {},
   "source": [
    "## set up config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f3a464-fe45-477b-8815-cebe102228f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up config\n",
    "snapshot_date_str = \"2023-01-01\"\n",
    "\n",
    "start_date_str = \"2023-01-01\"\n",
    "end_date_str = \"2024-12-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8787cd-0a84-4332-b2ab-a9efdc2a597a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate list of dates to process\n",
    "def generate_first_of_month_dates(start_date_str, end_date_str):\n",
    "    # Convert the date strings to datetime objects\n",
    "    start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n",
    "    \n",
    "    # List to store the first of month dates\n",
    "    first_of_month_dates = []\n",
    "\n",
    "    # Start from the first of the month of the start_date\n",
    "    current_date = datetime(start_date.year, start_date.month, 1)\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        # Append the date in yyyy-mm-dd format\n",
    "        first_of_month_dates.append(current_date.strftime(\"%Y-%m-%d\"))\n",
    "        \n",
    "        # Move to the first of the next month\n",
    "        if current_date.month == 12:\n",
    "            current_date = datetime(current_date.year + 1, 1, 1)\n",
    "        else:\n",
    "            current_date = datetime(current_date.year, current_date.month + 1, 1)\n",
    "\n",
    "    return first_of_month_dates\n",
    "\n",
    "dates_str_lst = generate_first_of_month_dates(start_date_str, end_date_str)\n",
    "dates_str_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5cddd1-b87b-42dd-8158-8ecf9bd6b839",
   "metadata": {},
   "source": [
    "## Build Bronze Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1874a1-7485-4d53-8d21-f288ad309a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bronze datalake\n",
    "bronze_lms_directory = \"datamart/bronze/lms/\"\n",
    "\n",
    "if not os.path.exists(bronze_lms_directory):\n",
    "    os.makedirs(bronze_lms_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef27a306-7fdc-4c82-aa84-5b9703fc2e19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run bronze backfill\n",
    "for date_str in dates_str_lst:\n",
    "    utils.data_processing_bronze_table.process_bronze_table(date_str, bronze_lms_directory, spark)\n",
    "    utils.data_processing_clickstream.process_bronze_clickstream(date_str, bronze_lms_directory, spark)\n",
    "    utils.data_processing_attributes.process_bronze_attributes(date_str, bronze_lms_directory, spark)\n",
    "    utils.data_processing_financials.process_bronze_financials(date_str, bronze_lms_directory, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea424c9-8361-4a66-977a-4850c0962941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect Bronze outputs for all datasets\n",
    "\n",
    "loan_bronze_df = utils.data_processing_bronze_table.process_bronze_table(date_str, bronze_lms_directory, spark)\n",
    "display(loan_bronze_df.toPandas())\n",
    "\n",
    "click_bronze_df = utils.data_processing_clickstream.process_bronze_clickstream(date_str, bronze_lms_directory, spark)\n",
    "display(click_bronze_df.toPandas())\n",
    "\n",
    "attr_bronze_df = utils.data_processing_attributes.process_bronze_attributes(date_str, bronze_lms_directory, spark)\n",
    "display(attr_bronze_df.toPandas())\n",
    "\n",
    "fin_bronze_df = utils.data_processing_financials.process_bronze_financials(date_str, bronze_lms_directory, spark)\n",
    "display(fin_bronze_df.toPandas())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d767bf08-b027-43bd-a695-43b5217fd756",
   "metadata": {},
   "source": [
    "## Build Silver Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd1733-5963-4536-987b-528e045dba71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bronze datalake\n",
    "silver_loan_daily_directory = \"datamart/silver/loan_daily/\"\n",
    "\n",
    "if not os.path.exists(silver_loan_daily_directory):\n",
    "    os.makedirs(silver_loan_daily_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccd38ec-e3f9-4c4e-8128-09b521f0f1b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run silver backfill\n",
    "for date_str in dates_str_lst:\n",
    "    utils.data_processing_silver_table.process_silver_table(date_str, bronze_lms_directory, silver_loan_daily_directory, spark)\n",
    "    utils.data_processing_clickstream.process_silver_clickstream(date_str, bronze_lms_directory, silver_loan_daily_directory, spark)\n",
    "    utils.data_processing_attributes.process_silver_attributes(date_str, bronze_lms_directory, silver_loan_daily_directory, spark)\n",
    "    utils.data_processing_financials.process_silver_financials(date_str, bronze_lms_directory, silver_loan_daily_directory, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d68da-e596-4c89-bdd3-2aef969e35ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loan_silver_df = utils.data_processing_silver_table.process_silver_table(date_str, bronze_lms_directory, silver_loan_daily_directory, spark)\n",
    "display(loan_silver_df.toPandas())\n",
    "\n",
    "click_silver_df = utils.data_processing_clickstream.process_silver_clickstream(date_str, bronze_lms_directory, silver_loan_daily_directory, spark)\n",
    "display(click_silver_df.toPandas())\n",
    "\n",
    "attr_silver_df = utils.data_processing_attributes.process_silver_attributes(date_str, bronze_lms_directory, silver_loan_daily_directory, spark)\n",
    "display(attr_silver_df.toPandas())\n",
    "\n",
    "fin_silver_df = utils.data_processing_financials.process_silver_financials(date_str, bronze_lms_directory, silver_loan_daily_directory, spark)\n",
    "display(fin_silver_df.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f9b5fe-a68c-4aa5-8c3e-8c0f59b654a6",
   "metadata": {},
   "source": [
    "## EDA on credit labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608e1387-c2d4-4b41-b5aa-425ad6376e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set DPD label definition\n",
    "dpd = 30\n",
    "\n",
    "# Path to the folder containing all parquet files\n",
    "folder_path = silver_loan_daily_directory\n",
    "\n",
    "# Filter only loan daily parquet files\n",
    "loan_files = [\n",
    "    f for f in glob.glob(os.path.join(folder_path, '*'))\n",
    "    if 'silver_loan_daily_' in os.path.basename(f)\n",
    "]\n",
    "\n",
    "if not loan_files:\n",
    "    raise FileNotFoundError(\"No loan parquet files found. Please check the directory or file naming.\")\n",
    "\n",
    "# Read and merge all loan parquet files\n",
    "df = spark.read.parquet(*loan_files)\n",
    "\n",
    "# Check schema to avoid reading the wrong table\n",
    "if \"loan_start_date\" not in df.columns:\n",
    "    raise ValueError(\n",
    "        f\"The current DataFrame does not contain 'loan_start_date'. \"\n",
    "        f\"Actual columns are: {df.columns}. \"\n",
    "        f\"Please check if non-loan parquet files were mixed in.\"\n",
    "    )\n",
    "\n",
    "# Filter only loans that started before January 1, 2024\n",
    "df = df.filter(col(\"loan_start_date\") < datetime.strptime(\"2024-01-01\", \"%Y-%m-%d\"))\n",
    "\n",
    "# Create DPD flag (1 if dpd >= threshold, else 0)\n",
    "df = df.withColumn(\"dpd_flag\", F.when(col(\"dpd\") >= dpd, 1).otherwise(0))\n",
    "\n",
    "# Select actual bad loans (e.g., installment_num == 10)\n",
    "actual_bads_df = df.filter(col(\"installment_num\") == 10)\n",
    "\n",
    "# Convert to pandas for visualization\n",
    "pdf = df.toPandas()\n",
    "\n",
    "# Group by 'mob' and calculate bad rate\n",
    "grouped = pdf.groupby('mob')['dpd_flag'].mean().sort_index()\n",
    "\n",
    "# Plot the bad rate curve\n",
    "grouped.plot(kind='line', marker='o')\n",
    "plt.title(f'DPD: {dpd}')\n",
    "plt.xlabel('mob')\n",
    "plt.ylabel('bad rate')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b200137d-ca20-42b9-a3df-0b662024a899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5a6b17-8978-405a-8b04-6c6f4c7a3e52",
   "metadata": {},
   "source": [
    "## Build gold table for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4fca41-8b52-47e9-bf40-b063a0d7c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bronze datalake\n",
    "gold_label_store_directory = \"datamart/gold/label_store/\"\n",
    "\n",
    "if not os.path.exists(gold_label_store_directory):\n",
    "    os.makedirs(gold_label_store_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7874eb-aa70-4cd4-81ca-1e955e788b44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # run gold backfill\n",
    "# for date_str in dates_str_lst:\n",
    "#     utils.data_processing_gold_table.process_labels_gold_table(date_str, silver_loan_daily_directory, gold_label_store_directory, spark, dpd = 30, mob = 6)\n",
    "#     utils.data_processing_gold_features.process_gold_customer_feature_store(date_str, silver_loan_daily_directory, gold_label_store_directory, spark)\n",
    "\n",
    "# Gold backfill for labels + feature store\n",
    "for date_str in dates_str_lst:\n",
    "    utils.data_processing_gold_table.process_labels_gold_table(\n",
    "        date_str, \n",
    "        silver_loan_daily_directory, \n",
    "        gold_label_store_directory, \n",
    "        spark, \n",
    "        dpd=30, \n",
    "        mob=6)\n",
    "\n",
    "    gold_feature_df = utils.data_processing_gold_features.process_gold_customer_feature_store(\n",
    "        date_str, \n",
    "        silver_loan_daily_directory,  \n",
    "        gold_label_store_directory, \n",
    "        spark)\n",
    "\n",
    "    print(f\"[GOLD] {date_str}: Feature store row count = {gold_feature_df.count()}, columns = {len(gold_feature_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96439e0a-282e-4081-8865-ce9e2779757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_gold_df = utils.data_processing_gold_table.process_labels_gold_table(date_str, silver_loan_daily_directory, gold_label_store_directory, spark, dpd = 30, mob = 6).dtypes\n",
    "print(label_gold_df.dtypes)\n",
    "\n",
    "feature_gold_df = utils.data_processing_gold_features.process_gold_customer_feature_store(ate_str, silver_loan_daily_directory, gold_label_store_directory, spark)\n",
    "print(feature_gold_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eeb8a3-7737-4556-a85c-e844b47f6454",
   "metadata": {},
   "source": [
    "## inspect label store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abc72e2-90ed-46da-8c6e-599573d54049",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = gold_label_store_directory\n",
    "files_list = [folder_path+os.path.basename(f) for f in glob.glob(os.path.join(folder_path, '*'))]\n",
    "df = spark.read.option(\"header\", \"true\").parquet(*files_list)\n",
    "print(\"row_count:\",df.count())\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc20833e-9653-4c4c-9ce0-0023cca719b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845dda2a-1659-407d-9e98-df1dbdb3f025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
